{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Matric for Classification\n",
    "\n",
    "1. Accuracy\n",
    " - in classification problems it is the number of correct predicitons made by the model\n",
    "    divided by the total number of predictions.\n",
    " - Accuracy is useful when the target classes are well balanced. Having roughly the same\n",
    "     amount of either data sets.\n",
    " - It is not a good choice with unbalances classes\n",
    " - Calcuated as: (true positive + true negative)/total\n",
    " - The reverse of this, which is the Misclasification Rate(Error Rate) is calculated as:\n",
    "     (false positive + false negative)/total. This indicates how often the model is wrong.\n",
    "     \n",
    "2. Recall\n",
    "\n",
    "- Ability of a model to find all the relevant cases within dataset.\n",
    "- It is the number of true positives divided by the number of true positives by the number\n",
    "  of false negatives\n",
    "  \n",
    "3. Precision \n",
    "\n",
    " - Ability of a classification model to identify only the relevant data points.\n",
    " - Precision is defined by the number of true positives plus the number of false positives.\n",
    " \n",
    "*Recall and Precision\n",
    "- ofter you have the trade-off between Recall and Precision. While Recall expresses the\n",
    " ability to find all the relevant instances in a dataset, precision expresses the proportion\n",
    " of data points our model says was relevant actually were relevant.\n",
    " \n",
    "4. F1-Score\n",
    "- in cases where we want to find an optimal blend of precision and recall we can combine the \n",
    "  two metrics using what is called the F1 score. It is the harmonic mean of the precision and \n",
    "  recall taking both metrics into account in the following equation:\n",
    "  \n",
    "  F1 = 2*(precision * recall)/ (precision + recall)\n",
    "  \n",
    "  We use the harmonic mean instead of a simple average because it punishes extreme values.\n",
    "  A classification with a precision of 1.0 and a recall of 0.0 has simple average of 0.5\n",
    "  but an F1 score of 0.\n",
    "  \n",
    "  \n",
    "  \n",
    "* We can also view all our correctly classified versus incorrectly classified images in the\n",
    "form of a confusion matrix\n",
    "\n",
    "#*-MLPs with one hidden layer are capable of approximating any continuous function.\n",
    "\n",
    "# Introducion to the Perceptron\n",
    "\n",
    "We have inputs, weights, bias term, activation function and output\n",
    "\n",
    "#Multiple Perceptro Network\n",
    "https://pathmind.com/wiki/multilayer-perceptron\n",
    "\n",
    "- A multilayer (3 or more) perceptron (MLP) is a deep, artificial neural network. \n",
    "-MLPs with one hidden layer are capable of approximating any continuous function.\n",
    "-It is composed of more than one perceptron. They are composed of an\n",
    "    input layer to receive the signal, an output layer that makes a decision\n",
    "    or prediction about the input, and in between those two, an arbitrary number\n",
    "    of hidden layers that are the true computational engine of the MLP.\n",
    "\n",
    "\n",
    "#Cost Functions\n",
    "\n",
    "- used to evaluate the perfomance of a neuron. We cam use it to measure how far off we are\n",
    "    from the expected value.\n",
    "    \n",
    "#Gradient Descent\n",
    "- it is an optimization algorithm for finding the minimum of a function.\n",
    "- to find a local minimum, we take steps proportional to the negative of the gradient.\n",
    "- using gradient descent we can figure out the best parameters for minimizing our cost, for\n",
    "    example, finding the best values for the weights of the neuron inputs\n",
    "    \n",
    "#Backpropagation\n",
    "- it is used to calculate the error contribution of each neuron after a batch of data is\n",
    "    processed. It relies heavily on the chain rule to go back through the network and\n",
    "    calculate the errors.\n",
    "- it works by calculating the error at the output and then distributes back through the\n",
    "    network layers. It requires a known desired output for each input value\n",
    "    (supervised learning)\n",
    "    \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
